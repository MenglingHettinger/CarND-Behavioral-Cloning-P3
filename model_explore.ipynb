{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/mengling/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers import Conv2D, Lambda, MaxPooling2D, Dropout, Activation, Convolution2D, Cropping2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "measurements = [] \n",
    "with open('/home/mengling/Desktop/train/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        data.append(line)\n",
    "        measurements.append(line[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = [float(i) for i in measurements if i != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([186.,  16.,  17.,  11.,  21.,  16.,   9.,  32.,  21.,  24.,  22.,\n",
       "         19.,  31.,  20.,  22.,  36.,  21.,  47.,  21.,  42.,  27.,  32.,\n",
       "         50.,  26.,  78.,  24.,  40.,  98.,  45.,  41., 121.,  64., 171.,\n",
       "         75., 237.,  69.,  78., 345., 123., 404., 115., 115., 478., 111.,\n",
       "        430., 111., 125., 451., 100., 123.,  72.,  71., 261.,  74., 283.,\n",
       "         78.,  89., 275.,  88.,  72., 262.,  80., 240.,  68., 162.,  44.,\n",
       "         63., 112.,  36., 118.,  42.,  24.,  67.,  30.,  30.,  56.,  20.,\n",
       "         44.,  26.,  33.,  42.,  31.,  26.,  16.,  20.,  24.,  17.,  39.,\n",
       "         17.,   4.,  34.,  18.,  25.,   7.,  11.,  18.,  12.,  25.,   7.,\n",
       "        224.]),\n",
       " array([-1.  , -0.98, -0.96, -0.94, -0.92, -0.9 , -0.88, -0.86, -0.84,\n",
       "        -0.82, -0.8 , -0.78, -0.76, -0.74, -0.72, -0.7 , -0.68, -0.66,\n",
       "        -0.64, -0.62, -0.6 , -0.58, -0.56, -0.54, -0.52, -0.5 , -0.48,\n",
       "        -0.46, -0.44, -0.42, -0.4 , -0.38, -0.36, -0.34, -0.32, -0.3 ,\n",
       "        -0.28, -0.26, -0.24, -0.22, -0.2 , -0.18, -0.16, -0.14, -0.12,\n",
       "        -0.1 , -0.08, -0.06, -0.04, -0.02,  0.  ,  0.02,  0.04,  0.06,\n",
       "         0.08,  0.1 ,  0.12,  0.14,  0.16,  0.18,  0.2 ,  0.22,  0.24,\n",
       "         0.26,  0.28,  0.3 ,  0.32,  0.34,  0.36,  0.38,  0.4 ,  0.42,\n",
       "         0.44,  0.46,  0.48,  0.5 ,  0.52,  0.54,  0.56,  0.58,  0.6 ,\n",
       "         0.62,  0.64,  0.66,  0.68,  0.7 ,  0.72,  0.74,  0.76,  0.78,\n",
       "         0.8 ,  0.82,  0.84,  0.86,  0.88,  0.9 ,  0.92,  0.94,  0.96,\n",
       "         0.98,  1.  ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7263f6940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.hist(measurements, bins=100, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(samples, batch_size=batch_size):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        from sklearn.utils import shuffle\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            # Read center, left and right images from a folder containing Udacity data and my data\n",
    "            for batch_sample in batch_samples:\n",
    "                center_name = '/home/animesh/Documents/CarND/CarND-Behavioral-Cloning-P3/data2/IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(center_name)\n",
    "                center_image = cv2.cvtColor(center_image, cv2.COLOR_BGR2RGB)\n",
    "                left_name = '/home/animesh/Documents/CarND/CarND-Behavioral-Cloning-P3/data2/IMG/'+batch_sample[1].split('/')[-1]\n",
    "                left_image = cv2.imread(left_name)\n",
    "                left_image = cv2.cvtColor(left_image, cv2.COLOR_BGR2RGB)\n",
    "                right_name = '/home/animesh/Documents/CarND/CarND-Behavioral-Cloning-P3/data2/IMG/'+batch_sample[2].split('/')[-1]\n",
    "                right_image = cv2.imread(right_name)\n",
    "                right_image = cv2.cvtColor(right_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                center_angle = float(batch_sample[3])\n",
    "\n",
    "                # Apply correction for left and right steering\n",
    "                correction = 0.20\n",
    "                left_angle = center_angle + correction\n",
    "                right_angle = center_angle - correction\n",
    "\n",
    "                # Randomly include either center, left or right image\n",
    "                num = random.random()\n",
    "                if num <= 0.33:\n",
    "                    select_image = center_image\n",
    "                    select_angle = center_angle\n",
    "                    images.append(select_image)\n",
    "                    angles.append(select_angle)\n",
    "                elif num>0.33 and num<=0.66:\n",
    "                    select_image = left_image\n",
    "                    select_angle = left_angle\n",
    "                    images.append(select_image)\n",
    "                    angles.append(select_angle)\n",
    "                else:\n",
    "                    select_image = right_image\n",
    "                    select_angle = right_angle\n",
    "                    images.append(select_image)\n",
    "                    angles.append(select_angle)\n",
    "\n",
    "                # Randomly horizontally flip selected images with 80% probability\n",
    "                keep_prob = random.random()\n",
    "                if keep_prob >0.20:\n",
    "                    flip_image = np.fliplr(select_image)\n",
    "                    flip_angle = -1*select_angle\n",
    "                    images.append(flip_image)\n",
    "                    angles.append(flip_angle)\n",
    "\n",
    "                # Augment with images of different brightness\n",
    "                # Randomly select a percent change\n",
    "                change_pct = random.uniform(0.4, 1.2)\n",
    "\n",
    "                # Change to HSV to change the brightness V\n",
    "                hsv = cv2.cvtColor(select_image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "                hsv[:, :, 2] = hsv[:, :, 2] * change_pct\n",
    "                # Convert back to RGB and append\n",
    "\n",
    "                bright_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "                images.append(bright_img)\n",
    "                angles.append(select_angle)\n",
    "\n",
    "                ## Randomly shear image with 80% probability\n",
    "                shear_prob = random.random()\n",
    "                if shear_prob >=0.20:\n",
    "                    shear_range = 40\n",
    "                    rows, cols, ch = select_image.shape\n",
    "                    dx = np.random.randint(-shear_range, shear_range + 1)\n",
    "                    #    print('dx',dx)\n",
    "                    random_point = [cols / 2 + dx, rows / 2]\n",
    "                    pts1 = np.float32([[0, rows], [cols, rows], [cols / 2, rows / 2]])\n",
    "                    pts2 = np.float32([[0, rows], [cols, rows], random_point])\n",
    "                    dsteering = dx / (rows / 2) * 360 / (2 * np.pi * 25.0) / 10.0\n",
    "                    M = cv2.getAffineTransform(pts1, pts2)\n",
    "                    shear_image = cv2.warpAffine(center_image, M, (cols, rows), borderMode=1)\n",
    "                    shear_angle = select_angle + dsteering\n",
    "                    images.append(shear_image)\n",
    "                    angles.append(shear_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "\n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(og_path, img_path, batch_size=batch_size):\n",
    "    samples, images, measurements = [], [], []\n",
    "    with open(log_path) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "        \n",
    "    num_samples = len(samples)\n",
    "\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        from sklearn.utils import shuffle\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            # Read center, left and right images from a folder containing Udacity data and my data\n",
    "            for batch_sample in batch_samples:\n",
    "                for i in range(3):\n",
    "                    source_path = batch_sample[i]\n",
    "                    filename = source_path.split(\"/\")[-1]\n",
    "                    current_path = img_path + filename\n",
    "                    image = cv2.imread(current_path)\n",
    "                    images.append(image)\n",
    "                    # center image\n",
    "                    if i == 0: \n",
    "                        measurement = float(line[3])\n",
    "                    # left image\n",
    "                    elif i == 1:\n",
    "                        measurement = float(line[3]) + 0.1\n",
    "                    elif i == 2:\n",
    "                        measurement = float(line[3]) - 0.1 \n",
    "                    measurements.append(measurement)\n",
    "            \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(log_path, img_path, augment=True):\n",
    "    lines, images, measurements = [], [], []\n",
    "    with open(log_path) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "    for line in lines:\n",
    "        source_path = line[0]\n",
    "        filename = source_path.split(\"/\")[-1]\n",
    "        current_path = img_path + filename\n",
    "        image = cv2.imread(current_path)\n",
    "        images.append(image)\n",
    "        measurement = float(line[3])\n",
    "        measurements.append(measurement)\n",
    "    if augment:\n",
    "        augmented_images, augmented_measurements = [], []\n",
    "        for image, measurement in zip(images, measurements):\n",
    "            augmented_images.append(image)\n",
    "            augmented_measurements.append(measurement)\n",
    "            augmented_images.append(cv2.flip(image, 1))\n",
    "            augmented_measurements.append(measurement * -1.0)\n",
    "        return augmented_images, augmented_measurements\n",
    "    else:\n",
    "        return images, measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(log_path, img_path, augment=True):\n",
    "    lines, images, measurements = [], [], []\n",
    "    with open(log_path) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "    for line in lines:\n",
    "        for i in range(3):\n",
    "            source_path = line[i]\n",
    "            filename = source_path.split(\"/\")[-1]\n",
    "            current_path = img_path + filename\n",
    "            image = cv2.imread(current_path)\n",
    "            images.append(image)\n",
    "            # center image\n",
    "            if i == 0: \n",
    "                measurement = float(line[3])\n",
    "            # left image\n",
    "            elif i == 1:\n",
    "                measurement = float(line[3]) + 0.1\n",
    "            elif i == 2:\n",
    "                measurement = float(line[3]) - 0.1                \n",
    "        measurements.append(measurement)\n",
    "    if augment:\n",
    "        augmented_images, augmented_measurements = [], []\n",
    "        for image, measurement in zip(images, measurements):\n",
    "            augmented_images.append(image)\n",
    "            augmented_measurements.append(measurement)\n",
    "            augmented_images.append(cv2.flip(image, 1))\n",
    "            augmented_measurements.append(measurement * -1.0)\n",
    "        return augmented_images, augmented_measurements\n",
    "    else:\n",
    "        return images, measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1, measurements1 = read_data('/home/mengling/Desktop/train01/driving_log.csv', \n",
    "                                   '/home/mengling/Desktop/train01/IMG/', augment=True)\n",
    "images2, measurements2 = read_data('/home/mengling/Desktop/train01b/driving_log.csv', \n",
    "                                   '/home/mengling/Desktop/train01b/IMG/', augment=True)\n",
    "images3, measurements3 = read_data('/home/mengling/Desktop/train01c/driving_log.csv', \n",
    "                                   '/home/mengling/Desktop/train01c/IMG/', augment=True)\n",
    "images4, measurements4 = read_data('/home/mengling/Desktop/train01d/driving_log.csv', \n",
    "                                   '/home/mengling/Desktop/train01d/IMG/', augment=True)\n",
    "images5, measurements5 = read_data('/home/mengling/Desktop/train02/driving_log.csv', \n",
    "                                   '/home/mengling/Desktop/train02/IMG/', augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.concatenate([images1, images2, images3, images4])\n",
    "measurements = np.concatenate([measurements1, measurements2, measurements3, measurements4])\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22194, 160, 320, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70, 25), (0,0))))\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2, 2), activation='relu', dim_ordering=\"tf\"))\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2, 2), activation='relu', dim_ordering=\"tf\"))\n",
    "model.add(Dropout(p=0.7))\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2, 2), activation='relu', dim_ordering=\"tf\"))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', dim_ordering=\"tf\"))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', dim_ordering=\"tf\"))\n",
    "model.add(Dropout(p=0.7))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(p=0.7))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the model on training data, and save it as model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17755 samples, validate on 4439 samples\n",
      "Epoch 1/10\n",
      "17755/17755 [==============================] - 17s - loss: 0.0190 - val_loss: 0.1032\n",
      "Epoch 2/10\n",
      "17755/17755 [==============================] - 17s - loss: 0.0182 - val_loss: 0.1040\n",
      "Epoch 3/10\n",
      "17755/17755 [==============================] - 16s - loss: 0.0182 - val_loss: 0.1033\n",
      "Epoch 4/10\n",
      "17755/17755 [==============================] - 16s - loss: 0.0181 - val_loss: 0.1032\n",
      "Epoch 5/10\n",
      "17755/17755 [==============================] - 16s - loss: 0.0181 - val_loss: 0.1035\n",
      "Epoch 6/10\n",
      "17755/17755 [==============================] - 16s - loss: 0.0181 - val_loss: 0.1032\n",
      "Epoch 7/10\n",
      "17755/17755 [==============================] - 16s - loss: 0.0181 - val_loss: 0.1032\n",
      "Epoch 8/10\n",
      "17755/17755 [==============================] - 16s - loss: 0.0181 - val_loss: 0.1032\n",
      "Epoch 9/10\n",
      "17755/17755 [==============================] - 16s - loss: 0.0181 - val_loss: 0.1032\n",
      "Epoch 10/10\n",
      "17755/17755 [==============================] - 16s - loss: 0.0181 - val_loss: 0.1032\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True)\n",
    "\n",
    "model.save('/home/mengling/projects/carnd/Term1/CarND-Behavioral-Cloning-P3/model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
